{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import optuna as opt\n",
    "from optuna.samplers import TPESampler\n",
    "# suppress info logs\n",
    "opt.logging.set_verbosity(opt.logging.WARNING)\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 760\n",
    "DATA_DIR = Path(\"../../../ready_data\")\n",
    "\n",
    "N_OPTUNA_TRIALS = 50\n",
    "K_FOLDS = 3 # for both outer and inner cv\n",
    "T_ES = 20 # threshold # consecutive non-improvement rounds for early stopping\n",
    "\n",
    "df_train = pd.read_parquet(DATA_DIR/\"100K18F_train_main.parquet.snappy\")\n",
    "df_test = pd.read_parquet(DATA_DIR/\"100K18F_test_main.parquet.snappy\")\n",
    "\n",
    "print(f\"Shape of the training data : {df_train.shape}\")\n",
    "print(f\"Shape of the test data : {df_test.shape}\")\n",
    "\n",
    "X_train, y_train = df_train.drop(['r_useful', 'r_id'], axis=1).values, df_train['r_useful'].values\n",
    "X_test, y_test = df_test.drop(['r_useful', 'r_id'], axis=1).values, df_test['r_useful'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_model = XGBRegressor(\n",
    "    booster=\"gbtree\",\n",
    "    n_jobs=-1, # use all CPUs.\n",
    "    tree_method=\"gpu_hist\", # use GPU\n",
    "    predictor=\"gpu_predictor\",\n",
    "    objective=\"reg:squarederror\",\n",
    "    eval_metric=[\"rmse\"],\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "# Mean imputation and standardisation\n",
    "XGB_pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer()),\n",
    "    (\"ss\", StandardScaler()),\n",
    "    (\"xgb\", XGB_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_hp_appender(hp_dict):\n",
    "    '''Return dictionary where every key has \"xgb__\" appended.'''\n",
    "    new_dict = {}\n",
    "    for key, val in hp_dict.items():\n",
    "        new_dict[\"xgb__\" + key] = val\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_objective(trial, model, X, y):\n",
    "    print(f\"{time.strftime('%H:%M:%S', time.localtime())} | Running Optuna Trial: {trial.number}\")\n",
    "    \n",
    "    # sample hyperparameters from optuna\n",
    "    hyperparams = {\n",
    "        \"n_estimators\":trial.suggest_int('n_estimators', 1, 501, step=25),\n",
    "        \"learning_rate\" : trial.suggest_float('learning_rate', 0.001, 0.5, log=True),\n",
    "        \"max_depth\" : trial.suggest_int(\"max_depth\", 2, 20),\n",
    "        # subsample of observations for each iteration\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1, step=0.1),\n",
    "        # subsample of features for each iteration\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1, step=0.1),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 1),\n",
    "    }\n",
    "    print(f\"with hyperparameters: {hyperparams}\")\n",
    "    hyperparams = XGB_hp_appender(hyperparams)\n",
    "    model.set_params(**hyperparams)\n",
    "\n",
    "    # Inner CV Loop\n",
    "    avg_score = -cross_val_score(model, X, y,\n",
    "        scoring=\"neg_root_mean_squared_error\", cv=KFold(K_FOLDS)).mean()\n",
    "    print(f\"complete! average cv RMSE: {avg_score}\")\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class early_stopping_check_callback:\n",
    "    def __init__(self, threshold):\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def __call__(self, study, trial):\n",
    "        # stop study if the number of consecutive trials with no improvement is\n",
    "        # at least the threshold.\n",
    "        if trial.number - study.best_trial.number >= self.threshold:\n",
    "            print(\"==== EARLY STOPPING ACTIVATED ====\")\n",
    "            study.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = early_stopping_check_callback(T_ES)\n",
    "out_cv = KFold(K_FOLDS)\n",
    "outer_cv_results = {\n",
    "    \"rmse\": [],\n",
    "    \"mae\": [],\n",
    "    \"opt_hp\": []\n",
    "}\n",
    "\n",
    "# Outer CV Loop\n",
    "for cv_train_ii, cv_val_ii in out_cv.split(X_train, y_train):\n",
    "    # extract outer cv data for this fold\n",
    "    cv_X_train, cv_y_train = X_train[cv_train_ii], y_train[cv_train_ii]\n",
    "    cv_X_val, cv_y_val = X_train[cv_val_ii], y_train[cv_val_ii]\n",
    "    \n",
    "    # Optuna Loop (encloses Inner CV Loop)\n",
    "    # note: inner cv should be within since the hyperparemeter sampling changes\n",
    "    # based on model performance, which changes based on data.\n",
    "    study = opt.create_study(direction='minimize', sampler=TPESampler(seed=RANDOM_SEED))\n",
    "    study.optimize(\n",
    "        lambda trial: optuna_objective(trial, XGB_pipe, cv_X_train, cv_y_train),\n",
    "        n_trials=N_OPTUNA_TRIALS,\n",
    "        callbacks=[early_stopping_cb]) # early stopping\n",
    "    best_params = XGB_hp_appender(study.best_params)\n",
    "\n",
    "    # evaluate model with best hyperparameters according to Inner CV Loop\n",
    "    XGB_pipe.set_params(**best_params)\n",
    "    # fit on all training data for this fold\n",
    "    XGB_pipe.fit(cv_X_train, cv_y_train)\n",
    "    # predict on all validation data for this fold\n",
    "    y_preds = XGB_pipe.predict(cv_X_val)\n",
    "\n",
    "    # calculate scores\n",
    "    rmse = mean_squared_error(cv_y_val, y_preds, squared=False)\n",
    "    mae = mean_absolute_error(cv_y_val, y_preds)\n",
    "\n",
    "    # save results for this iteration\n",
    "    outer_cv_results[\"rmse\"].append(rmse)\n",
    "    outer_cv_results[\"mae\"].append(mae)\n",
    "    outer_cv_results[\"opt_hp\"].append(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outer_cv_results)\n",
    "print(f\"mean nested CV RMSE: {np.mean(outer_cv_results['rmse'])}\")\n",
    "print(f\"mean nested CV MAE: {np.mean(outer_cv_results['mae'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('CS760')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d275a923d824725c8a5a1bac7b1c3fb204380710405e1dc55a9cc47165ea62c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
