{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import optuna as opt\n",
    "from optuna.samplers import TPESampler\n",
    "# suppress info logs\n",
    "opt.logging.set_verbosity(opt.logging.WARNING)\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractArrays(df):\n",
    "    '''Extracts feature matrix X and label array y from dataframe.'''\n",
    "    return df.drop(['r_useful', 'r_id'], axis=1).values, df['r_useful'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 760\n",
    "DATA_DIR = Path(\"../../ready_data\")\n",
    "\n",
    "N_OPTUNA_TRIALS = 50\n",
    "N_FOLDS = 5\n",
    "N_REPS = 6 # number of repetitions of CV\n",
    "T_ES = 20 # threshold # consecutive non-improvement rounds for early stopping\n",
    "\n",
    "df_train = pd.read_parquet(DATA_DIR/\"100K35F_train_main.parquet.snappy\")\n",
    "df_val = pd.read_parquet(DATA_DIR/\"100K35F_val_main.parquet.snappy\")\n",
    "df_test = pd.read_parquet(DATA_DIR/\"100K35F_test_main.parquet.snappy\")\n",
    "\n",
    "X_train, y_train = extractArrays(df_train)\n",
    "X_val, y_val = extractArrays(df_val)\n",
    "X_test, y_test = extractArrays(df_test)\n",
    "\n",
    "print(f\"Shape of the training data : {X_train.shape}\")\n",
    "print(f\"Shape of the val data : {X_val.shape}\")\n",
    "print(f\"Shape of the test data : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PREFIX = \"xgb\"\n",
    "XGB_model = XGBRegressor(\n",
    "    booster=\"gbtree\",\n",
    "    n_jobs=-1, # use all CPUs.\n",
    "    tree_method=\"gpu_hist\", # use GPU\n",
    "    predictor=\"gpu_predictor\",\n",
    "    objective=\"reg:squarederror\",\n",
    "    eval_metric=[\"rmse\"],\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Mean imputation and standardisation\n",
    "model_pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer()),\n",
    "    (\"ss\", StandardScaler()),\n",
    "    (MODEL_PREFIX, XGB_model)])\n",
    "\n",
    "# needed for setting parameters correctly in pipe\n",
    "def hp_appender(hp_dict):\n",
    "    '''Return dictionary where every key has the MODEL_PREFIX__ appended.'''\n",
    "    new_dict = {}\n",
    "    for key, val in hp_dict.items():\n",
    "        new_dict[MODEL_PREFIX + \"__\" + key] = val\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_objective(trial, model, X, y):\n",
    "    print(f\"{time.strftime('%H:%M:%S', time.localtime())} | Running Optuna Trial: {trial.number}\")\n",
    "    \n",
    "    # sample hyperparameters from optuna\n",
    "    hyperparams = {\n",
    "        \"n_estimators\":trial.suggest_int('n_estimators', 1, 501, step=5),\n",
    "        \"learning_rate\" : trial.suggest_float('learning_rate', 0.001, 0.5, log=True),\n",
    "        \"max_depth\" : trial.suggest_int(\"max_depth\", 2, 20),\n",
    "        # subsample of observations for each iteration\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1, step=0.1),\n",
    "        # subsample of features for each iteration\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1, step=0.1),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 1),\n",
    "    }\n",
    "    print(f\"with hyperparameters: {hyperparams}\")\n",
    "    hyperparams = hp_appender(hyperparams)\n",
    "    model.set_params(**hyperparams)\n",
    "\n",
    "    # Inner CV Loop\n",
    "    avg_score = -cross_val_score(model, X, y,\n",
    "        scoring=\"neg_root_mean_squared_error\", cv=KFold(N_FOLDS)).mean()\n",
    "    print(f\"complete! average cv RMSE: {avg_score}\")\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class early_stopping_check_callback:\n",
    "    def __init__(self, threshold):\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def __call__(self, study, trial):\n",
    "        # stop study if the number of consecutive trials with no improvement is\n",
    "        # at least the threshold.\n",
    "        if trial.number - study.best_trial.number >= self.threshold:\n",
    "            print(\"==== EARLY STOPPING ACTIVATED ====\")\n",
    "            study.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(X, y):\n",
    "    '''Obtains best hyperparameters using TPE sampling and cross-validation.'''\n",
    "    study = opt.create_study(direction='minimize', sampler=TPESampler(seed=RANDOM_SEED))\n",
    "    study.optimize(\n",
    "        lambda trial: optuna_objective(trial, model_pipe, X, y),\n",
    "        n_trials=N_OPTUNA_TRIALS,\n",
    "        callbacks=[early_stopping_check_callback(T_ES)]) # early stopping\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_score(model, hps, X_train, y_train, X_test, y_test):\n",
    "    model.set_params(**hp_appender(hps))\n",
    "    model.fit(X_train, y_train)\n",
    "    y_preds = model.predict(X_test)\n",
    "\n",
    "    # calculate scores\n",
    "    rmse = mean_squared_error(y_test, y_preds, squared=False)\n",
    "    mae = mean_absolute_error(y_test, y_preds)\n",
    "    return rmse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repetition_results = {\n",
    "    \"hp\": [],\n",
    "    \"rmse\": [],\n",
    "    \"mae\": []\n",
    "}\n",
    "\n",
    "for rep_i in range(N_REPS):\n",
    "    print(f\"====== Running repetition: {rep_i} ======\")\n",
    "    # shuffle training data. Make sure each iteration uses different seed\n",
    "    cv_train = df_train.sample(frac=1, random_state=RANDOM_SEED+rep_i)\n",
    "    # extract X and y arrays\n",
    "    cv_X_train, cv_y_train = extractArrays(cv_train)\n",
    "    \n",
    "    # obtain best hyperparameters via cross-validation and TPE sampling.\n",
    "    best_params = get_best_model(cv_X_train, cv_y_train)\n",
    "    \n",
    "    rmse, mae = fit_and_score(\n",
    "        model_pipe, best_params,\n",
    "        cv_X_train, cv_y_train,\n",
    "        X_val, y_val)\n",
    "\n",
    "    # save results for this iteration\n",
    "    repetition_results[\"rmse\"].append(rmse)\n",
    "    repetition_results[\"mae\"].append(mae)\n",
    "    repetition_results[\"hp\"].append(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine train and val sets\n",
    "# https://stackoverflow.com/questions/33356442/when-should-i-use-hstack-vstack-vs-append-vs-concatenate-vs-column-stack\n",
    "X_train_val = np.vstack((X_train, X_val))\n",
    "y_train_val = np.hstack((y_train, y_val))\n",
    "print(X_train_val.shape)\n",
    "print(y_train_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = repetition_results['rmse']\n",
    "best_best_i = np.argmin(rmse) # best = minimum RMSE\n",
    "hp = repetition_results['hp']\n",
    "best_best_hp = hp[best_best_i]\n",
    "\n",
    "rmse, mae = fit_and_score(model_pipe, best_best_hp,\n",
    "    X_train_val, y_train_val, X_test, y_test)\n",
    "\n",
    "print(f\"Best overall HP:{best_best_hp}\")\n",
    "print(f\"Best overall RMSE: {rmse:.4}\")\n",
    "print(f\"Best overall MAE: {mae:.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(repetition_results)\n",
    "\n",
    "print(\"\\nRMSE\")\n",
    "print(f\"mean: {np.mean(rmse):.4}, stdev: {np.std(rmse):.4}\")\n",
    "\n",
    "print(\"MAE\")\n",
    "mae = repetition_results['mae']\n",
    "print(f\"mean: {np.mean(mae):.4}, stdev: {np.std(mae):.4}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('CS760')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d275a923d824725c8a5a1bac7b1c3fb204380710405e1dc55a9cc47165ea62c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
